{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T23:54:26.467387Z","iopub.status.busy":"2024-02-29T23:54:26.463687Z","iopub.status.idle":"2024-02-29T23:55:28.707851Z","shell.execute_reply":"2024-02-29T23:55:28.705666Z","shell.execute_reply.started":"2024-02-29T23:54:26.467284Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pdfminer.six in /opt/conda/lib/python3.10/site-packages (20231228)\n","Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six) (3.3.2)\n","Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six) (41.0.7)\n","Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n","Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.2)\n","Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.24.4)\n","Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.11.4)\n","Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (6.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.2)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (69.0.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\n","Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.24.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n"]}],"source":["!pip install pdfminer.six\n","!pip install gensim\n","!pip install nltk\n","!pip install spacy"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T23:53:20.379079Z","iopub.status.busy":"2024-02-29T23:53:20.378662Z","iopub.status.idle":"2024-02-29T23:53:21.427722Z","shell.execute_reply":"2024-02-29T23:53:21.426585Z","shell.execute_reply.started":"2024-02-29T23:53:20.379047Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-01T00:01:43.069270Z","iopub.status.busy":"2024-03-01T00:01:43.068841Z","iopub.status.idle":"2024-03-01T00:01:43.078523Z","shell.execute_reply":"2024-03-01T00:01:43.076660Z","shell.execute_reply.started":"2024-03-01T00:01:43.069239Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import requests\n","import os\n","import re\n","from pdfminer.high_level import extract_text\n","import glob\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from gensim import corpora, models\n","import gensim\n","import spacy\n","from spacy.lang.en.stop_words import STOP_WORDS\n","from collections import Counter"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T23:55:34.265094Z","iopub.status.busy":"2024-02-29T23:55:34.264413Z","iopub.status.idle":"2024-02-29T23:55:35.764098Z","shell.execute_reply":"2024-02-29T23:55:35.762861Z","shell.execute_reply.started":"2024-02-29T23:55:34.265056Z"},"trusted":true},"outputs":[],"source":["nlp = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T23:58:34.877087Z","iopub.status.busy":"2024-02-29T23:58:34.876655Z","iopub.status.idle":"2024-02-29T23:58:34.886421Z","shell.execute_reply":"2024-02-29T23:58:34.884956Z","shell.execute_reply.started":"2024-02-29T23:58:34.877056Z"},"trusted":true},"outputs":[],"source":["def preprocess_text(text):\n","    # Remove non-alphanumeric characters and extra whitespaces\n","    text = re.sub(r'\\W', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text)\n","    \n","    # Lemmatize text using spaCy\n","    doc = nlp(text)\n","    lemmatized_tokens = [token.lemma_ for token in doc if token.lemma_ not in STOP_WORDS]\n","    \n","    return lemmatized_tokens"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T23:53:41.826799Z","iopub.status.busy":"2024-02-29T23:53:41.826309Z","iopub.status.idle":"2024-02-29T23:53:41.835643Z","shell.execute_reply":"2024-02-29T23:53:41.834193Z","shell.execute_reply.started":"2024-02-29T23:53:41.826759Z"},"trusted":true},"outputs":[],"source":["def clean_and_preprocess_file(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        text = file.read()\n","    \n","    # Remove non-alphanumeric characters and extra whitespaces\n","    text = re.sub(r'\\W', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text)\n","    \n","    # Preprocess text\n","    tokens = preprocess_text(text)\n","    \n","    return tokens"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-03-01T00:07:27.356001Z","iopub.status.busy":"2024-03-01T00:07:27.355479Z","iopub.status.idle":"2024-03-01T00:07:27.363316Z","shell.execute_reply":"2024-03-01T00:07:27.362057Z","shell.execute_reply.started":"2024-03-01T00:07:27.355967Z"},"trusted":true},"outputs":[],"source":["def clean_and_preprocess_directory(directory='/kaggle/working/txt_directory'):\n","    documents = {}\n","    for filename in os.listdir(directory):\n","        if filename.endswith(\".txt\"):\n","            file_path = os.path.join(directory, filename)\n","            tokens = clean_and_preprocess_file(file_path)\n","            documents[filename] = tokens\n","    return documents"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-03-01T00:08:50.167943Z","iopub.status.busy":"2024-03-01T00:08:50.167471Z","iopub.status.idle":"2024-03-01T00:08:50.181432Z","shell.execute_reply":"2024-03-01T00:08:50.179918Z","shell.execute_reply.started":"2024-03-01T00:08:50.167911Z"},"trusted":true},"outputs":[],"source":["#Increase the threshold with more documents\n","def perform_topic_modeling(directory='/kaggle/working/txt_directory', num_topics=5, max_freq_threshold=1000):\n","    # Clean and preprocess documents\n","    documents = clean_and_preprocess_directory(directory)\n","    \n","    # Count word frequencies across all documents\n","    all_words = [word for doc in documents.values() for word in doc]\n","    word_counts = Counter(all_words)\n","    \n","    # Identify words to be filtered based on their frequency\n","    frequent_words = [word for word, freq in word_counts.items() if freq >= max_freq_threshold * len(all_words)]\n","    \n","    # Remove frequent words from documents\n","    cleaned_documents = {file_name: [word for word in doc if word not in frequent_words] for file_name, doc in documents.items()}\n","    \n","    # Create dictionary and corpus\n","    dictionary = corpora.Dictionary(cleaned_documents.values())\n","    corpus = [dictionary.doc2bow(doc) for doc in cleaned_documents.values()]\n","    \n","    # Build LDA model\n","    lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n","    \n","    # Get topics for each document\n","    document_topics = {}\n","    for file_name, doc_bow in zip(cleaned_documents.keys(), corpus):\n","        topics = lda_model.get_document_topics(doc_bow)\n","        document_topics[file_name] = topics\n","        \n","    for idx, topic in lda_model.print_topics(-1):\n","        print(f'Topic {idx}: {topic}\\n')\n","    \n","    return lda_model, document_topics"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["glob.glob('/kaggle/working/pdf_directory/*.pdf')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_pickle('/kaggle/input/semantic-scholar-retrieval/retrieved_data')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def extract_pdf_from_response(df_row, pdf_directory='/kaggle/working/pdf_directory'):\n","    \"\"\"\n","    This function takes the structure of the 'openAccessPdf' column of the semantic scholar\n","    api response dataset downloads the available pdfs in the specified directory, indexed\n","    with the paperid value.\n","    \n","    variables:\n","    - df_row: And iterable with a 'paperId' key and an 'openAccessPdf' key\n","    - pdf_directory: The folder in which the files will be stored\n","    \"\"\"\n","    \n","    if not os.path.exists(pdf_directory):\n","        os.makedirs(pdf_directory)\n","    \n","    if df_row['openAccessPdf']:\n","        try:\n","            req = requests.get(df_row['openAccessPdf']['url'])\n","            if req.status_code == 200:\n","                with open(pdf_directory + '/' + df_row['paperId'] + '.pdf', 'wb') as f:\n","                    f.write(req.content)\n","        except Exception as e:\n","            pass"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def extract_plain_text_from_pdf(pdf_directory='/kaggle/working/pdf_directory', txt_directory='/kaggle/working/txt_directory'):\n","    all_files = glob.glob(pdf_directory + '/*.pdf')\n","    \n","    if not os.path.exists(txt_directory):\n","        os.makedirs(txt_directory)\n","        \n","    for i in all_files:\n","        file_id = i.split('.')[0].split('/')[-1]\n","        print(i)\n","        whole_text = extract_text(i)\n","        with open(txt_directory + '/' + file_id + '.txt', 'w') as f:\n","            f.write(whole_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df[~df['openAccessPdf'].isna()].head(5).apply(extract_pdf_from_response, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["extract_plain_text_from_pdf()"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-03-01T00:08:53.451145Z","iopub.status.busy":"2024-03-01T00:08:53.450702Z","iopub.status.idle":"2024-03-01T00:08:58.291191Z","shell.execute_reply":"2024-03-01T00:08:58.289995Z","shell.execute_reply.started":"2024-03-01T00:08:53.451111Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Topic 0: 0.010*\"channel\" + 0.009*\"10\" + 0.009*\"OFDM\" + 0.008*\"org\" + 0.008*\"modulation\" + 0.008*\"2023\" + 0.008*\"frequency\" + 0.007*\"signal\" + 0.007*\"doi\" + 0.007*\"http\"\n","\n","Topic 1: 0.016*\"image\" + 0.015*\"EC50\" + 0.014*\"occupancy\" + 0.012*\"1\" + 0.012*\"0\" + 0.011*\"I\" + 0.011*\"cluster\" + 0.011*\"voxel\" + 0.010*\"level\" + 0.010*\"use\"\n","\n","Topic 2: 0.000*\"1\" + 0.000*\"system\" + 0.000*\"feature\" + 0.000*\"use\" + 0.000*\"5\" + 0.000*\"2\" + 0.000*\"0\" + 0.000*\"4\" + 0.000*\"I\" + 0.000*\"10\"\n","\n","Topic 3: 0.000*\"feature\" + 0.000*\"1\" + 0.000*\"system\" + 0.000*\"0\" + 0.000*\"use\" + 0.000*\"test\" + 0.000*\"2\" + 0.000*\"item\" + 0.000*\"datum\" + 0.000*\"3\"\n","\n","Topic 4: 0.023*\"feature\" + 0.013*\"system\" + 0.012*\"test\" + 0.011*\"use\" + 0.011*\"component\" + 0.011*\"item\" + 0.010*\"1\" + 0.010*\"code\" + 0.009*\"case\" + 0.009*\"function\"\n","\n"]}],"source":["lda_model, document_topics = perform_topic_modeling()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-03-01T00:08:58.294371Z","iopub.status.busy":"2024-03-01T00:08:58.293546Z","iopub.status.idle":"2024-03-01T00:08:58.302429Z","shell.execute_reply":"2024-03-01T00:08:58.301099Z","shell.execute_reply.started":"2024-03-01T00:08:58.294324Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'272cc6496c3b3de74090de7451ffcd0d19351b92.txt': [(1, 0.9995926)],\n"," 'fb64d10afa0c5270415abbf2f5ac33618e45e0ad.txt': [(4, 0.99987113)],\n"," '45272efd2973b6d1f830e6c01daeb9bbbb3769d6.txt': [(1, 0.9998108)],\n"," 'ecdf7d78813ef689fc0238cc9e53e0b1ef686e2f.txt': [(0, 0.99975824)]}"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["document_topics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4490776,"sourceId":7694498,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
