{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions import retrieve_data\n",
    "from pandas import read_parquet, DataFrame, concat, read_pickle\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from glob import glob\n",
    "\n",
    "from os import getenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rate limit with key:\n",
    "\n",
    "    1 request per second for the following endpoints:\n",
    "        /paper/batch\n",
    "        /paper/search\n",
    "        /recommendations\n",
    "    10 requests / second for all other calls\n",
    "\n",
    " Additionally, all unauthenticated users share a limit of 5,000 requests per 5 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sugiero que cada quien cree su propia API key, y de esta manera aumentar \n",
    "## el volumen de requests por segundo\n",
    "API_KEY = getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data of DB sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = read_json('data/dict_split_4.json', orient='index')\n",
    "#df.reset_index(inplace=True, names=['db_id'])\n",
    "#df['db_id'] = df['db_id'].astype(str)\n",
    "#df.to_parquet('data/data_4.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156240"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_parquet('data/data_4.parquet', \n",
    "                  columns=['db_id','title','year']\n",
    "                  )  \n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('data/api_request_results/documents/*')\n",
    "files = [f.split('/')[-1][5:-4] for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153244"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['db_id'].isin(files)]\n",
    "df = df.sample(len(df), ignore_index=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [01:33, 16.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for Human-Robot Site Survey and Sampling for Space Exploration, AIAA-2006-7425 (3913693)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [07:11, 29.25s/it]"
     ]
    }
   ],
   "source": [
    "for row in tqdm(df.itertuples()):\n",
    "    \n",
    "    res = retrieve_data.request_semantic_scholar(row.title,\n",
    "                                                 api_key=API_KEY, \n",
    "                                                 fields=retrieve_data.QUERY_FIELDS)\n",
    "    \n",
    "    if res['status_code']==200:\n",
    "        data = res.get('data')\n",
    "        if data:\n",
    "            df_res = DataFrame.from_dict(data)\n",
    "            \n",
    "            df_res['db_id'] = row.db_id\n",
    "            df_res['db_title'] = row.title\n",
    "            df_res['db_year'] = row.year\n",
    "            \n",
    "            df_res.to_pickle(f'data/api_request_results/documents/data_{row.db_id}.zip', \n",
    "                             compression= {\n",
    "                                'method': 'zip',\n",
    "                                'compresslevel': 9  # Nivel máximo de compresión para ZIP\n",
    "                                }\n",
    "                            )\n",
    "        else:\n",
    "            print(f'No data for {row.title} ({row.db_id})')\n",
    "        sleep(1)\n",
    "    elif res['status_code']==429:\n",
    "        print('Too many requests in {row.title} ({row.db_id}). Waiting 180 seconds')\n",
    "        sleep(180)\n",
    "    else: \n",
    "        print('Error:', res)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2996/2996 [00:12<00:00, 236.14it/s]\n",
      "/tmp/ipykernel_5366/1332076495.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  retrieved_data = concat([read_pickle(f) for f in tqdm(glob('api_request_results/documents/*'))])\n"
     ]
    }
   ],
   "source": [
    "retrieved_data = concat([read_pickle(f) for f in tqdm(glob('data/api_request_results/documents/*'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_data.to_pickle(f'data/api_request_results/retrieved_data.zip', \n",
    "                             compression= {\n",
    "                                'method': 'zip',\n",
    "                                'compresslevel': 9  # Nivel máximo de compresión para ZIP\n",
    "                                }\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "url = 'https://bitcoin.org/bitcoin.pdf'\n",
    "response = get_request(url)\n",
    "with open('sample.pdf', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "'''   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
